# AI Agent Management System

A scalable system for managing, monitoring, and orchestrating AI agents built with FastAPI, LangChain, and SQLite.

## ğŸš€ Features

- **Agent Management**
  - Create and configure AI agents
  - Start/stop agent execution
  - Monitor agent status and performance
  - Real-time updates via WebSocket

- **Task Execution**
  - Assign tasks to agents
  - Track task progress
  - Store execution history
  - Handle errors and retries

- **Resource Management**
  - Database persistence
  - Memory management
  - Tool integration
  - State tracking

## ğŸ› ï¸ Technical Stack

- **Backend**: FastAPI
- **Database**: SQLite
- **AI Framework**: LangChain
- **LLM Integration**: OpenAI
- **API Documentation**: Swagger/OpenAPI

## ğŸ“‹ Prerequisites

- Python 3.9+
- OpenAI API key
- Virtual environment management

## ğŸ”§ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/ai-agent-manager.git
cd ai-agent-manager
```

2. Create and activate virtual environment:
```bash
# Create virtual environment
python3 -m venv venv

# Activate (Mac/Linux)
source venv/bin/activate
# Activate (Windows)
# venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create `.env` file:
```bash
# .env
OPENAI_API_KEY=your_api_key_here
DATABASE_URL=sqlite:///agents.db
API_HOST=127.0.0.1
API_PORT=8000
```

## ğŸš€ Running the Application

1. Start the server:
```bash
python run.py
```

2. Access the API documentation:
```
http://127.0.0.1:8000/docs
```

## ğŸ“– API Documentation

### Endpoints

#### Agents
- `POST /api/v1/agents/` - Create a new agent
- `POST /api/v1/agents/{agent_id}/start` - Start an agent
- `POST /api/v1/agents/{agent_id}/stop` - Stop an agent
- `GET /api/v1/agents/{agent_id}` - Get agent status

#### Tasks
- `POST /api/v1/agents/{agent_id}/tasks` - Execute a task

#### WebSocket
- `WS /api/v1/ws/agents/{agent_id}` - Real-time agent updates

### Example Usage

```python
# Create an agent
POST /api/v1/agents/
{
    "name": "research_agent",
    "config": {
        "model_name": "gpt-3.5-turbo",
        "temperature": 0.7
    }
}

# Execute a task
POST /api/v1/agents/{agent_id}/tasks
{
    "type": "research",
    "input": "What are the latest developments in AI?"
}
```

## ğŸ—„ï¸ Project Structure

```
aim/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # API endpoints and routing
â”‚   â”œâ”€â”€ config/        # Configuration and settings
â”‚   â”œâ”€â”€ core/          # Core business logic
â”‚   â””â”€â”€ database/      # Database models and setup
â”œâ”€â”€ tests/             # Test files
â”œâ”€â”€ .env              # Environment variables
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ run.py            # Application entry point
```

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_agent_manager.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸ”’ Security

- All endpoints require authentication (TODO)
- API keys are managed via environment variables
- Database connections are properly managed
- Input validation on all endpoints

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## âœ¨ Future Enhancements

- [ ] Add authentication and authorization
- [ ] Implement rate limiting
- [ ] Add more agent tools and capabilities
- [ ] Enhance monitoring and analytics
- [ ] Add support for multiple LLM providers
- [ ] Implement agent collaboration features

## ğŸ› Known Issues

- Currently only supports single-user mode
- Limited to OpenAI's API
- Basic error handling

## ğŸ“ Support

For support, please open an issue in the GitHub repository or contact the maintainers.

---

Made with â¤ï¸ by [Your Name]